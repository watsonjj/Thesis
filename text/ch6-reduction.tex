\chapter{\label{ch6-reduction}Waveform Reduction} 

\minitoc

\notes[inline,caption={}]{
	\section{Plan}
	\subsection{Topics}
	\begin{itemize}
		\item Charge Extraction Methods
		\item Image cleaning
		\item Shower reconstruction
		\begin{itemize}
			\item Hillas
			\item Impact
			\item model
			\item Neural Nets
			\item ++
		\end{itemize}
		\item Energy Reconstruction
		\item Direction Reconstruction
	\end{itemize}
	\subsection{Questions}
	\begin{itemize}
		\item ?
	\end{itemize}
}

\section{Introduction}

Methods for retrieving information about the Cherenkov shower have been a primary component of the Imaging Atmospheric Cherenkov Technique since its inception. Early techniques such as those used in the first observation of TeV Gamma rays from the Crab nebula \cite{Weekes1989} are still utilised in modern \glspl{iact}. These techniques are also applicable to \gls{cta} telescopes, and as \gls{cta} is a large consortium which consists of the worldwide \gls{iact} community, the developers of the reduction approaches for previous \glspl{iact} have brought them forward to \gls{cta}. However, due to:
\begin{enumerate}[label=(\alph*)]
	\item \gls{cta} is to consist of the most advanced \glspl{iact} to date, with higher shower imaging resolution and telescope multiplicity than has previously been available,
	\item the capabilities of digital signal processing has significantly increased in the past decade,
\end{enumerate}
the opportunity for more advanced and more successful algorithms exists for \gls{cta}. Some effort has already been made in this direction, but it is an aspect that is expected to constantly evolve and improve during the lifetime of \gls{cta}. In this chapter I will provide an overview of the existing and in-development reduction techniques utilised to extract the Cherenkov shower signal from the waveforms, and my involvement in designing a charge-extraction technique for \gls{chec-s}. With regards to the \gls{cta} data levels (Figure~\ref{fig:dataflow}), this chapter is mostly concerned with the step from \textit{DL0} to \textit{DL1}.

\section{Charge Extraction Methods}

The immediate step after the waveform calibration is the extraction of signal from the waveforms provided by each camera individually. As a result of the low-level calibration detailed in \ref{ch5-calibration}, the waveforms from each \gls{cta} camera exist in a common state, with no remaining dependencies on the electronics they were produced with. Therefore, the extraction techniques are typically applicable to all \gls{cta} cameras. 

The extraction of signal from a waveform is a very generic problem, allowing for the utilisation of common signal processing techniques that are not unique to Cherenkov shower analysis. The goal is to extract as much signal from the pulse created by the Cherenkov shower light, while simultaneously limiting the inclusion of noise factors\change{reference where noise talked about, talk about all the contributing factors (noise etc.) to waveforms in ch2}. Two quantities are extracted in this stage: the signal charge in each pixel, and the signal arrival time per pixel. 

The total signal charge in a pixel, i.e. the total number of photo-electrons released from the \gls{pmt}'s photocathode, is proportional to the total area below the pulse corresponding to the Cherenkov photons. If the waveforms were completely free of noise, and the readout window was large enough to capture the full Cherenkov signal, a simple integration of the entire readout would be a satisfactory approach for obtaining the signal charge. However, as we do not have the luxury of perfect waveforms, more complex methods are designed. Charge extraction algorithms typically consist of two aspects: how the signal pulse is found, and how the pulse is integrated.

\subsection{Peak Finding} \label{peakfinding}

Two factors must be considered when finding the signal pulse of a Cherenkov shower. Firstly, the majority of camera pixels will not contain any Cherenkov signal while still containing noise. A peak finding technique that assumes a signal exists in the readout will be biased, as it will mistake the noise for signal. Secondly, due to the nature of Cherenkov showers (Chapter~ \change{reference where the time gradient of Cherenkov showers are described}), those pixels with Cherenkov signal will have different arrival times due to the time evolution of the Cherenkov image \change{figure of peak time?}. This time gradient across the image is especially apparent for bright showers at a large core distance from the telescope. The most successful peak-finding technique is one that best accounts for those two factors. Some simple techniques used to define a peak time from a waveform include:
\begin{itemize}
	\item \textbf{Local Peak Finding}: Each waveform is treated independently from the other. The maximum point in the waveform is treated as the peak/arrival time. This approach is intrinsically biased to assume every waveform contains a signal; therefore, in the absence of a Cherenkov signal, the largest noise pulse will be extracted, resulting in a higher total charge than should be obtained.
	\item \textbf{Global Peak Finding}: The waveform from every pixel is combined into an average, from which the maximum point is treated as the peak time for every pixel. This technique is only useful if a large portion of the camera is simultaneously illuminated, such as by a laser in the case of lab commissioning and calibration runs.
	\item \textbf{Neighbour Peak Finding}: The waveforms from the neighbouring pixels are combined into an average, from which the maximum point is treated as the peak time for the pixel-of-interest. This technique is often preferred for Cherenkov images as it has a reduced charge bias (especially if the pixel-of-interest's waveform is not included in the average); pixels with Cherenkov signal typically have neighbours that also contain Cherenkov signal at a correlated time, while the neighbours of empty pixels only contain noise, and therefore a peak time that is uncorrelated to the noise is chosen.
	\item \textbf{Fixed Peak Value}: Due to a reliable definition of the camera trigger and subsequent electronic chain, the position of the pulse in the waveform could consistently be known a-priori, allowing for a fixed peak time. However, this method requires a larger integration window size in order to capture the full pulse in the tail of the Cherenkov shower, which occur at a later time than the initial photons which trigger the camera, therefore resulting in a larger noise included in the signal. However, this technique usually contains the least bias, as no signal is assumed to exist.
\end{itemize}

 A more complex peak-finding technique is the \textit{Gradient Peak Finding} approach. This approach was designed for the VERITAS telescope \cite{Holder2005}\cite{Cogan2006}\cite{Cogan2007}, but is applicable to any \gls{iact} telescope that allows the dynamic specification of an integration window. \textit{Gradient Peak Finding} utilises the gradient profile of the photon arrival time for gamma-induced Cherenkov showers, described in Section~\ref{section:photon_arrival_time} and illustrated in Figure~\change{chec-m pulse time figure}. This peak-finding technique is a two-pass approach performed by first extracting the signal using one of the other methods. The timing information contained within the pixels that survive cleaning (Section~\ref{section:image_cleaning}) can then be used to obtain a relation between ``distance along primary image axis'', $D_{ax}$, and the pulse time, $T_0$. Figure~\change{figure with geometry} illustrates the geometry of $D_{ax}$ with respect to the pixel position. Using the obtained relation between $D_{ax}$ and $T_0$, an example of which is shown in Figure~\change{figure of Dax versus T0 for checm figure}, an unbiased pulse time is obtained for each pixel depending on its position along the image axis.

These peak-finding methods have been described in relation to the maximum of the signal pulse, however they may instead use other characteristic positions of the pulse, such as the half-maximum time on the rising edge, or the centre of gravity of the pulse. Additionally, more advanced peak-finding techniques may up-sample (possibly by zero-padding in the frequency domain via a Fourier transform) or interpolate the signal to obtain a more precise peak time \cite{Cogan2006, Cogan2007}, or even apply low-pass filters in order to remove low frequency baseline noise. The peak finding should be done in conjunction with any timing corrections (\ref{section:timing_corrections}) that may be required.

\subsection{Integration}

Once the peak time has been obtained, the simplest approach to extract the signal is to define an integration window centred about this time. The size of the window needs to be large enough to capture sufficient signal from the pulse, but small enough that not too much noise (\gls{nsb}, dark counts, afterpulsing) is included within the window, thereby maximising the signal-to-noise. Additionally, the camera's pulse shape may not be symmetric, so a better signal-to-noise may be achieved by shifting the window a few samples with respect to the peak time. The optimal integration window size and shift for the \gls{chec-s} waveforms is found to be \SI{5}{samples} and \SI{2}{samples} (i.e. \SI{5}{ns} and \SI{2}{ns}), respectively, according to the investigations performed in \ref{a3-extractors}.

Beyond the simple ``boxcar'' integrator method (where every sample integrated has a weight of 1), other more advanced strategies may define their own alternative approach to extract the charge. One example is the fitting of the signal pulse, with an analytical description of the expected pulse, or with a more unconstrained description such as a cubic spline. A second complex approach is the use of digital filters, which can be used in combination with knowledge of the pulse shape to robustly extract the signal even in the presence of high noise. Such a technique has been designed and adopted for \gls{gct}, referred to as the \textit{Cross-Correlation} method. Due to its adoption and sophistication, it is described here in more detail. 

\subsubsection{Cross Correlation} \label{section:crosscorrelation}

Cross-correlation is a common signal processing technique used as a measure of the similarity between two signals as a function of the displacement in time applied to one of the signals. Given a continuous function $f(t)$ defined between $0 \le t \le T$ and a second continuous function $g(t)$, the cross-correlation between the two functions ($f \star g$) is defined as 
\begin{equation} \label{eq:cc1}
(f \star g)(\tau) = \int_0^T \overline{f}(t)g(t + \tau)dt,
\end{equation}
where $\overline{f}(t)$ is the complex conjugate of $f(t)$ and $\tau$ is the time displacement (also referred to as the ``lag'') between the two functions \cite{wolfram-crosscorrelate}. In descriptive terms, by varying $\tau$, $g(t + \tau)$ will slide past $f(t)$. The cross-correlation for a value of $\tau_1$ is then the integral across $t$ of the product between $f(t)$ and $g(t + \tau_1)$. For a discreet function that is real-valued, such as a sampled waveform, Equation~\ref{eq:cc1} can instead be defined as
\begin{equation} \label{eq:cc2}
(f \star g)\lbrack n \rbrack = \sum_{m=0}^N f\lbrack m \rbrack g\lbrack m + n\rbrack,
\end{equation}
where $N$ is the total number of samples in the waveform and $m$ is the sample displacement. 

An illustration of the \textit{cross-correlation} approach being applied on a \gls{chec-s} waveform is shown in Figure~\change{figure showing the cross-correlation at a few different times, and the different stages, 3 axes, maybe for a low illumination? mention I implemented \ref{eq:cc2} in Python}. Through utilising a template of the expected pulse shape in the absence of noise (hereafter referred to as the ``reference pulse'') features inside the waveform that are correlated with the reference pulse shape are emphasized, while features that do not, such as the electronic noise, are suppressed. Therefore, the peaks in the cross-correlation result correspond to the displacements where the signals match best, and the values of the peaks correspond to an weighted integral of the entire waveform, and can be used as an extracted charge value.

The reference pulse we use for the cross-correlation was obtained via probing the input analogue signal on the \gls{target} module and averaged on an oscilloscope. It was then normalised such that cross-correlation between it, and the reference pulse normalised to have an integral of 1, has a maximum value of 1. This normalisation ensures that the cross-correlation result is in units of \si{mV ns}, and allows an easy conversion into \si{mV} for ``peak-height'' investigations.  An optimised implementation of cross-correlation exists in |scipy.ndimage.correlate1d| \cite{scipy-crosscorrelate}, where the waveforms for every pixel are processed in parallel.

\change{mention negatives of the cc approach, like the emphasis of nsb and cc, here or in appendix?}

\subsection{Approaches Adopted by Other IACTs}

Some examples of approaches adopted by other telescopes are outlined below, to provide an overview of techniques considered by other \glspl{iact}.

\subsubsection{MAGIC}

Members of the MAGIC telescope, \textcite{Albert2008}, performed a study comparing the techniques proposed for their signal reconstruction. Four approaches were compared: \textit{fixed-window}, \textit{sliding-window} with amplitude-weighted time, \textit{cubic spline fit} with integral or amplitude extraction, and \textit{digital filter}. It was concluded that the digital filter, which relies on knowledge of the signal shape to minimise the noise contributions, provided a charge reconstruction with acceptable bias and minimal variance, while remaining stable in the occurrence of small variations in pulse shape and position.

\subsubsection{VERITAS}

Similar to the aforementioned study for the MAGIC telescope, a comparison of charge extraction approaches was performed for VERITAS \cite{Holder2005, Cogan2006, Cogan2007}. Specifically, the extraction methods compared included a \textit{simple-window} using a-priori knowledge of the Cherenkov pulse time in the trace, a \textit{dynamic-window} which slides across the trace to find the Cherenkov pulse, a \textit{trace-fit} evaluator with fits the trace with two exponential functions which respectively describe the rise and fall time of the pulse, a \textit{matched-filter} which ``uses a digital filter based on the assumed shape of the FADC pulse to integrate the charge'' \cite{Cogan2007}, and finally an implementation of the \textit{Gradient Peak Finding} approach described earlier in the chapter. At first glance, some of these approaches bear resemblance to those used by MAGIC, however there are slight differences: 
\begin{itemize}
	\item in the VERITAS pulse fitting technique, an attempt to describe the pulse analytically was made whereas the MAGIC approach used a more loosely defined spline
	\item the filter used by VERITAS is a cross-correlation in Fourier space, whereas the filter used by MAGIC is generated using their knowledge of the noise auto-correlation matrix
\end{itemize}

Either as a result of these differences, or due to the difference in the instruments themselves, the VERITAS \textit{matched-filter} appears to result in a worse reconstruction than one would expect from the conclusion reached by MAGIC. One might justify that this degradation of signal extraction with the \textit{matched-filter} for higher amplitudes is due to a change in pulse shape at higher amplitudes, thereby requiring a different "assumed FADC pulse shape", but it is not clear if that is what is occurring here\change{Garret: However, a thorough investigation of this particular reconstruction is beyond the scope of this work}. These studies conclude that the \textit{matched-filter} ''holds promise`` for reconstructing low charges, whereas while the \textit{trace-fit} performs extremely poor for the low charges (as expected), it performs the best for amplitudes > 4 photoelectrons \cite{Cogan2007}.

\subsubsection{H.E.S.S.}

The standard mode of charge extraction for the \gls{hess} telescopes is to integrate $N$ samples with respect to a fixed, but regularly verified, signal time \cite{Aharonian2004}. \gls{hess} camera electronics underwent an upgrade in 2015/2016, subsequently allowing for the update of the standard extraction mode to also output time-of-maximum and time-over-threshold, and also allowed for full sample readout enabling the utilisation of more complex charge extraction techniques \cite{Klepser2017}\cite{Chalme-Calvet2015}.

\subsubsection{ASTRI}

Contrary to the other techniques described in this section, \gls{astri} took the alternative direction of a hardware-implemented charge extraction, utilising their \gls{citiroc} \gls{asic}. The pulse from their \gls{sipmt} is amplified and shaped (with both a high-gain and low-gain channel) with a constant shaping time of \SI{37.5}{ns}. The maximum of the shaped peak-height is then converted into an integrated charge, achieving no more than \SI{1}{\percent} introduced systematic error \cite{Impiombato2017}. The \textit{DL0} and \textit{DL1} formats are therefore identical in \gls{astri}'s case as the charge-extracted value is provided in place of waveforms. However, while this charge-extraction technique is optimised for the \gls{astri} electronics, it removes the flexibility of being able to dynamically select a charge-extraction technique within the software, and adopting new software-based techniques that may be designed in the future.

\subsection{Performance Assessment}

Deciding on which charge extraction method to use is not trivial - as shown in the above discussion, different cameras may perform better with different algorithms. This is anticipated in \pkg{ctapipe} (\ref{ch4-software}), where different |ChargeExtractors| can easily be selected at runtime depending on the camera source.

The assessment technique typically used for charge extractors in the context of \gls{cta} is the Charge Resolution (Section~\ref{section:cr}). A performance assessment of charge extraction techniques for \gls{chec-s} can be found in Appendix~\ref{a3-extractors}.

\section{Next Steps}

The resulting images of the extracted signal per triggered telescope is only the first stage of many to retrieve the properties of the Cherenkov-shower progenitor particle: direction, energy, and class. The direction is necessary to retrieve in order to obtain the source's position and spatial morphology. The energy is desired for studies of the source's spectrum. The class of the progenitor particle (gamma-ray, electron, or cosmic-ray hadron) is required in order to identify the gamma-rays among the cosmic-ray background. All the information required to obtain these progenitor particle properties is contained within the image of extracted charge.

Pixels containing signal from the Cherenkov shower are identified an image cleaning method such as the tailcuts approach: any pixels above a certain signal threshold are kept, and any neighbouring pixels that are above a lower signal threshold are also kept. The thresholds are optimised per telescope using Monte Carlo simulations. The resulting pixels are then parametrised in terms of their second moments. This parametrisation is a predominant \gls{iact} analysis technique that has been utilised in the majority of \gls{iact} experiments. It was first formalised by \textcite{} and has subsequently been known as the Hillas parametrisation. This technique utilises the elliptical shape of the gamma-induced shower images, and provides values for the centre of gravity of the ellipse, its primary axis position and orientation, its width, and its length (Figure~\change{hillas parameterisation figure}.

Using a two-pass selection cut on the images

As shown in Figure~\ref{}



\begin{itemize}
\item The primary axis of the ellipse in the Cherenkov shower image represents the major axis of the Cherenkov shower. Therefore, the location of the source can be found along the primary axis of the ellipse. 
\item The total amount of signal detected from the Cherenkov shower (image \textit{size}) is a direct measure of the total energy released as Cherenkov light, and therefore is a direct measure of the progenitor particle's energy (Section~\change{section in introduction where it is shown that the majority of energy of the gamma-ray is release as cherenkov light}. However, the intensity of light received from the showers is inversely proportional to the distance squared. With knowledge of the distance to the shower core combined with 

Therefore, the combination of shower impact distance and image \textit{size} provide an estimation of the particle's energy.
\item 
\end{itemize}



direction is obtained from the primary axis of the 

As explained in Section 2.1.3, the major axis of the ellipse represents the
shower axis of the extended air shower. In particular, one side of the major
axis points towards the location of the source.

The extraction of this information is much more reliable through the use of the stereoscopic combination of the images from telescopes which detected the Cherenkov shower. However, while the problem of degeneracy in obtaining the location of the source with a single telescope is a difficult problem to overcome, it is not an impossible one.


Reconstruction of showers with a single telescope is more difficult; 

The ability to reconstruct showers with single telescopes is hampered by
the inherent degeneracy in determining which side of the camera field of view (FOV) the shower originated in. In a single telescope analysis, the source location is assumed to lie along the primary image axis, and the distance to it from the image centroid can be calculated according to Lessard et al. (2001). Use

As the focus of this thesis is on the low-level performance of the \gls{gct} cameras, an extended overview of the next stages involved shower reconstruction is not included. However, a brief description of the simple approaches used in the immediate next steps are supplied as context for the results described in \ref{ch8-pipeline}. For a full overview of the next stages in Cherenkov shower reduction, refer to the following publications \change{add publications, perhaps in list?}.

With knowledge of the the 

The purpose of the reduction of \gls{iact} waveforms is to recovery 

Resulting from the extraction of signal from the waveforms, an image of the Cherenkov shower for each of the triggered telescopes is obtained. The purpose of these images is to 


The sum of the charge in each pixel containing a part of the shower is a measure of the total energy released as Cherenkov radiation, which, as explained in Chapter~\ref{ch1-intro}, is a measure of the energy of the shower progenitor particle (cosmic or gamma-ray) \change{make sure to talk about this in introduction. maybe use a more direct reference than just the chapter}. The primary image axis is a measure of the direction of the Cherenkov shower


\section{Image Cleaning} \label{section:image_cleaning}

Once a charge per pixel is obtained, the next stage in reduction is to select the pixels which contain signal from the Cherenkov shower, in order to ease the parametrisation. 

\subsection{Tailcut Cleaning}

\subsection{Wavelets}

\section{Shower Parameterisation}

\subsection{Hillas}

\subsection{Model and Model++}

\subsection{ImPACT}

\subsection{Neural Nets}

\section{$\gamma$-Hadron Separation}

\section{Energy Reconstruction}

\section{Direction Reconstruction}



\change[inline]{advanced techniques that don't fit into these categories, machine learning, photon counting}
