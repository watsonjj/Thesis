\chapter{\label{ch3-architecture}The CTA System Architecture} 

\minitoc

\section{Introduction}

Due to the large scope of \gls{cta}, in both its construction and operation, a formal approach towards a system architecture was adopted \cite{Dazzi2018}. One important aspect within this architecture is the distinction between the \gls{cta} Consortium and the \gls{cta} Observatory. The \gls{cta} Consortium is a group of scientists responsible for directing the science goals of the observatory, and for developing software and hardware (including cameras), which are supplied to the observatory as in-kind contributions. The consortium consists of 200 institutes across 31 countries~\cite{cta-consortium}. Conversely, the CTA Observatory is the major astronomical facility that acquires the science data and delivers them to a wide user community as an open observatory. The \gls{cta} Observatory gGmbH is the legal entity for \gls{cta} in the preparation for the implementation of the \gls{cta} Observatory, and works in close cooperation with the consortium during this process \cite{cta-observatory}.

The purpose of the \gls{cta} Architecture is to ensure a coherent view of the functionality and capabilities of \gls{cta}. The \gls{cta} Architecture can then drive the pre-construction phase to guarantee:
\begin{itemize}
\item a coherent development process,
\item the seamless integration of the developed units into the final array,
\item and that the performance of the final array is capable of meeting its science goals.
\end{itemize}
During this chapter I will describe two concepts that are connected to the \gls{cta} Architecture that are important in the context of this thesis. Firstly, the \gls{cta} requirements which all cameras, including \gls{chec}, must meet. Secondly, the descriptions of how data are handled in \gls{cta}, including the data flow and data level definitions.

\section{Requirements}

In order to ensure the science goals of \gls{cta} are achievable, and that the observatory remains operational for the full 30 year life-time, certain standards must be upheld by all components of the observatory; this is the purpose of the \gls{cta} requirements. The requirements cover every aspect of the observatory, including: the survival and operation under different environmental conditions (e.g.\@ \requirementref{B-ENV-1120 Earthquake collapse prevention (South)}, \requirementref{B-ENV-0320 Survival humidity}), the time allowed by the analysis pipeline for processing (e.g.\@ \requirementref{A-OBS-0810 Data Processing Efficiency}), the reliability of telescope components (e.g.\@ \requirementref{B-TEL-0520 Structure Lifetime}), and the ability to meet the expected performance under different observation conditions (e.g.\@ \requirementref{PROG-0025 Differential Sensitivity under Low Moonlight - North}). In order for an in-kind contribution to be accepted, it must meet the requirements defined by the observatory. These requirements are therefore the standards against which we compare the performance of \gls{chec}, and are the primary drivers in my development of the low-level calibration and analysis. However, there exists more than 60 requirements specifically tailored for the cameras. Consequently, the full review of the camera is a large undertaking that extends beyond the scope of this thesis. Instead, only the requirements that have relevance to the topics of this thesis are discussed.

It is important to note that the requirements, located on the \gls{cta} Jama website~\cite{cta-jama}, are currently under review and therefore subject to change. A major change that is currently under way at the time of this writing is the redefinition from units of photoelectrons to photons. Originally, a common consolidated \gls{pmt} was envisioned to be used for all cameras in \gls{cta}, motivating the relevant requirements to be expressed in terms of photoelectrons. However, due to the advances in sensor technology and the adoption of \glspl{sipmt} by camera such as \gls{chec-s}, this assumption has led to problems with such a definition \cite{petophotons}. While one camera would measure X photoelectrons for a particular number of photons, a different camera (with a different \gls{pde}) would measure Y photoelectrons. Additionally, the definition of the requirements in photoelectrons encourages the cameras to be optimised in terms of their \glsf{enf}, potentially at the cost of its \glsf{pde}. The measurement in photons is therefore a much more coherent expression of signal for the array, which ensures requirements are stated in terms of the cameras ability to detect the Cherenkov-shower photons, instead of the cameras ability to resolve the number of photoelectrons produced after the photocathode. 

As the procedure of converting the requirements from photoelectrons to photons is ongoing, this thesis will contain reference to the photoelectron definition of the requirements. A copy of the requirements relevant to this thesis, in the form they exists in Jama at the time of this writing, are included alongside the discussion in this section. This is to ensure clarity about which version of the requirement definition is being referred to. Future investigations should check the latest requirement definition. \vfill

\subsection{B-TEL-1010 Charge Resolution} \label{section:cr}

\begin{requirement}{Jama Excerpt} 
	The required fractional charge resolution for Cherenkov signals in each Camera pixel for a specified background level of 0.125 photoelectrons/ns is given in the Figure below and Table attached. Charge measurements must be possible for 0-1000 photoelectron signals. The average charge resolution should be calculated for the reference Gamma-Ray Spectrum.
    
	\centering\includegraphics[width=0.8\linewidth]{charge_res_req}
	\captionof{figure}[Charge resolution requirement.]{Fractional rms charge resolution $\sigma_Q/Q$ per pixel for different Cherenkov light signal amplitudes, expressed in units of photoelectrons (p.e.). All sources of fluctuations, including Poisson fluctuations in photoelectron number, must be included. The true pixel charge $Q$ is that measured in an ideal detector with the same photon-detection efficiency. }\label{fig:charge_res_req}
    
\begin{itemize}
\item [Notes:] It is expected that this requirement is verified with reference to:

- Monte Carlo simulation of Cherenkov light from gamma-ray initiated showers (using a verified telescope model),

- Level-C Specification on Laboratory Measured \textit{Charge Resolution},

- Monte Carlo simulation of the laboratory test set-up (as a means of telescope model verification).

Note that between \SI{1000}{\pe} and \SI{2000}{\pe}, some sensitivity to increasing input signal must exist. \newline
This requirement applies to post-calibration (DL1) data. \newline
Note that this requirement will likely need to be expanded to cover performance at higher NSB levels.
\end{itemize}
\end{requirement}

\subsubsection{Definition}

The standard criterion for the low-level camera performance used in \gls{cta} is the \textit{Charge Resolution}. It encompasses both the bias and the standard deviation of the extracted charge versus the expected charge to provide a measure of the waveform, calibration, and charge reconstruction quality. Analogous to the Root-Mean-Square Error, the fractional \textit{Charge Resolution} $\frac{\sigma_Q}{Q_T}$ for a particular ``true charge'' $Q_T$ (the number of photoelectrons that would be measured directly after the photocathode of the sensor) is defined as:
\begin{equation} \label{eq:charge_res}
\frac{\sigma_Q}{Q_T} = \frac{1}{Q_T} \sqrt{\frac{\sum_{i=0}^N (Q_{M_i} - Q_T)^2}{N}},
\end{equation}
where $N$ is the total number of measured charges, $Q_{M_i}$, with that value of $Q_T$. The associated \gls{cta} requirement defines the maximum allowed values of $\frac{\sigma_Q}{Q_T}$ for values of $Q_T$ between \SIrange{1}{1000}{\pe}, which must be adhered to when resolving the signal for any camera in \gls{cta}.

\subsubsection{Requirement Derivation}

The uncertainty in charge reconstruction can be expressed in the form:
\begin{equation} \label{eq:charge_res_req}
\frac{\sigma_Q}{Q} = \frac{1}{Q} \sqrt{\sigma_0^2 + \sigma_{ENF}^2 Q + \sigma_g^2 Q^2},
\end{equation}
where $\sigma_0$ encapsulates noise contributions (electronic and \glsb{nsb}), $\sigma_{ENF}$ is determined from the \textit{Excess Noise Factor} (a measure of fluctuations in charge amplification), and $\sigma_g$ is the multiplicative errors in the calibration (i.e. the miscalibration) of the gain \cite{petophotons}\cite{Ohm2012}. $\sigma_0$ can be further expanded in terms of the two primary noise contributions:
\begin{equation} \label{eq:charge_res_nsb}
\sigma_0 = \sqrt{\mathit{NSB} \times t_w + n_e^2},
\end{equation}
i.e. the $\mathit{NSB}$ rate (which includes the \gls{dcr} for the purpose of this discussion) is coupled with the effective signal readout window size, $t_w = \SI{15}{ns}$, and summed with the electronic noise, $n_e$. A contribution from electronic noise of $n_e = \SI{0.87}{\pe}$ is assumed, combined with a value of $\mathit{NSB} = \SI{0.125}{\pe/ns}$ as defined in the requirement. A value of $\sigma_g = 0.1$ and $\sigma_{ENF} = 1.2$ is also assumed \cite{petophotons}. The resulting combination of miscalibration and noise factors in Equation~\ref{eq:charge_res_req} gives the \textit{Charge Resolution} requirement illustrated in Figure~\ref{fig:charge_res_req}.

\subsubsection{Approach}
As it is impossible to know the ``true charge'' generated by a Cherenkov signal in the field, Monte Carlo simulations must be relied upon in order to prove a camera meets this requirement. The process for achieving this is outlined in the notes to the requirement. It is expected that this requirement is validated in three ways:
\begin{enumerate}
\item With lab measurements where the camera in uniformly illuminated with a calibrated light source.
\item With simulations of the previous approach, in order to verify the simulation model of the camera.
\item With Monte Carlo simulations of Cherenkov signal incident on the full telescope model.
\end{enumerate}
The final item is the most important in confirming the requirements are met, as temporally-uniform illuminations do not sufficiently test the ability to find the signal pulse in the waveforms for the case of a Cherenkov-shower illumination. The prior items are important to verify that the \textit{Charge Resolution} result obtained in the final item is applicable to the real camera, i.e. the simulation model of the camera is accurate.

The software package \pkg{sim\_telarray} (Chapter~\ref{ch4-software}) stores the ``true charge'' generated after the photocathode for each shower event into the output file. Therefore, with an accurate simulation model of the camera, it is an appropriate package for investigating a camera's performance against this requirement. However, in order to ensure Poisson fluctuations in photoelectron number are included, as per the requirement, when using the ``true charge'' stored in the simulation file, the corrected form of Equation~\ref{eq:charge_res} is
\begin{equation} \label{eq:charge_res2}
\frac{\sigma_Q}{Q_T} = \frac{1}{Q_T} \sqrt{\frac{\sum_{i=0}^N (Q_{M_i} - Q_T)^2}{N} + Q_T}.
\end{equation}
With the form in Equation~\ref{eq:charge_res2}, a perfect detector that consistently reads-out a ``measured charge'' with an equal value to the ``true charge'' would hit the Poisson limit. This limit ensures realistic conclusions can be reached from the Monte Carlo simulations, as it is not physically possible to know the the ``true charge'' generated by the photocathode without fluctuations.

\subsection{B-TEL-1030 Time Resolution} \label{section:time_res}

\begin{requirement}{Jama Excerpt} 
The rms difference in the reconstructed signal arrival time for any two simultaneously illuminated pixels in the Camera with amplitudes of five photoelectrons must not exceed 2 ns. This is for a specified background level of 0.125 photoelectrons/ns.

\begin{itemize}
\item [Notes:] This requirement should be verified based on laboratory testing of a prototype at the specified background level.
\end{itemize}
\end{requirement}

A second important requirement concerning the signal inside the waveforms is the \textit{Time Resolution} requirement. While the capability to accurately locate the signal is already assessed by the \textit{Charge Resolution}, the purpose of this requirement is to instead ensure that the physical camera exhibits sensible behaviour with regards to the relative location of the signal between pixels, per event. The \textit{Time Resolution} $\sigma_T$ is essentially defined as the standard deviation of the difference in pulse time between every pixel in the camera, per event. This can be expressed as:
\begin{equation} \label{eq:time_res}
\sigma_T = \sqrt{\frac{\sum_{i=0}^N(\sum_{j=i+1}^N (T_{i-j} - \average{T}_{i-j})^2)}{\binom{N}{2} - 1}},
\end{equation}
\begin{equation} \label{eq:time_res2}
\average{T}_{i-j} = \frac{\sum_{i=0}^N(\sum_{j=i+1}^N T_{i-j})}{\binom{N}{2}},
\end{equation}
where $T_{i-j} = T_i - T_j$, i.e. the difference between the extracted pulse time $T_i$ for pixel $i$, and extracted pulse time $T_j$ for pixel $j$. $\binom{N}{2}$ is the binomial coefficient of the number of pixels $N$ ``choose'' 2, i.e. the total number of unique pixel combinations.

While the \textit{Time Resolution} $\sigma_T$ is calculated per event, the camera is better characterised by the mean and standard deviation of the \textit{Time Resolution} over multiple events. In order to meet the requirement, the \textit{Time Resolution} should be under \SI{2}{ns} for pixels with measured charges above \SI{5}{\pe}, in an environment containing an \gls{nsb} photon rate of at least \SI{0.125}{\pe/ns}. Any pixel timing corrections (described later in Section~\ref{section:timing_corrections}) that are required should be applied to the pulse time extracted from the waveform. Furthermore, the \textit{Time Resolution} does not need to be extracted with the same approach as used in the charge extraction, as long as the approach is justifiable.

\subsection{B-TEL-1295 Pixel Availability} \label{section:pixel_availability}

\begin{requirement}{Jama Excerpt}
During observations, at least 95\% of all camera pixels must be available and usable for data analysis. In addition, continuous regions of non-functioning pixels must not exceed 2\% of all camera pixels. Pixels excluded due to NSB levels beyond those required are not included in this budget.
\end{requirement}

This requirement sets a limit on the amount of ``dead'' pixels that a camera is allowed to have before the entire camera is considered to be unavailable. For \gls{chec}, which contains 2048 pixels, this imposes the following possible limitations:
\begin{itemize}
\item The camera may only have a maximum of 102 dead pixels. This allows 3 dead pixels per module.
\item The amount of continuous pixels that are allowed to be dead is 41, therefore if an entire \gls{target} module dies (each module containing 64 pixels), the camera's capabilities become insufficient for the \gls{cta} requirements. However, a maximum of two \gls{target} \glspl{asic} (each \gls{asic} containing 16 pixels) are allowed to die.
\end{itemize}

\begin{figure}
 	\centering
  	\includegraphics[width=0.8\textwidth]{high_level_data_model} 
	\caption[High-level data model hierarchy.]{Hierarchy of data element names including the data level, the classifications of data (based on their rate), and data elements/groups and sub-elements/groups \cite{Kosack2017}.}
	\label{fig:high_level_data_model}
\end{figure}

\begin{figure}
 	\centering
  	\includegraphics[height=0.9\textheight]{dataflow} 
	\caption[Simplified camera data flow.]{Simplified camera data flow, showing the \textit{EVT}-classified data streams (in green) and the processing steps between them (orange). The levels are grouped by the systems responsible for them.}
	\label{fig:dataflow}
\end{figure}


% \begin{wrapfigure}[37]{r}{0.32\textwidth}
% 	\includegraphics[width=0.32\textwidth]{dataflow}
% 	\caption[Simplified camera data flow.]{Simplified camera data flow, showing the \textit{EVT}-classified data streams (in green) and the processing steps between them (orange). The levels are grouped by the systems responsible for them.}
% 	\label{fig:dataflow}
% \end{wrapfigure}

\section{Data Level and Flow Model} \label{section:data_levels}

Further aspects of the \gls{cta} Architecture that are relevant to this work are the \textit{Data Processing Level} definitions, and the flow between them. These definitions dictate how the data obtained from the telescopes are handled within the observatory, and are important in ensuring each telescope adopts a similar processing chain to guarantee compatibility between themselves and the pipeline framework software. Figure~\ref{fig:high_level_data_model} shows the full hierarchy for data specification in the observatory. The \textit{Data Processing Level} indicates the progression of the data along the processing chain, the \textit{multiplicity} indicates the scope of the data, and the \textit{classification} designates the type of the data \cite{Kosack2017}. The levels are also split according to the system responsible for them (Figure~\ref{fig:dataflow}). The \gls{oes} is responsible for the control and monitoring of the \gls{cta} array components, the scheduling of observations, and the online data acquisition and processing. The responsibilities of the \gls{dpps} include processing the observational data into science data products, producing and analysing simulation data, and the long-term preservation of data products. Finally, the \gls{suss} will provide access to the high-level \gls{cta} data products, along with the corresponding \gls{cta} software to analyse them. It also provides a point of access for proposal submission.

As the primary focus of this thesis is on the waveform data from a single telescope, the rest of this section will be focussed on describing the data levels relevant to the \textit{EVT classification} (Figure~\ref{fig:high_level_data_model}), and the processes used to transition between them. These definitions are still undergoing development within \gls{cta}, but the foundations are generally agreed upon.
\begin{description}
\item[R0 \textit{(raw low-level)}:]
Raw waveform data, internal to the ``Camera Functional Unit'' (the official term given to an individual camera).
\item[R1 \textit{(raw common)}:]
Waveform data with \textit{R1 Calibration} applied. This low-level calibration is unique to the camera; the calibration's purpose is to remove the dependence on the behaviour of its specific electronics, such that \textit{R1} data is in a comment format for all telescopes. The \gls{chec} \textit{R1 Calibration} is described in Chapter~\ref{ch5-calibration}. A selection of gain-channel is also performed for cameras with two channels. The data at this level are serialised to a wire format, i.e. a block of data sent over a network in a common way between the telescopes. This data level is processed by the \textit{Online Analysis} pipeline in order to produce immediate science alerts. The \textit{R1} level therefore has its own set of (relaxed) requirements to adhere to (including its own \textit{Charge Resolution} requirement), ensuring that the minimum standard required for the \textit{Online Analysis} and \textit{Data Volume Reduction} is met. Further (potentially slower) calibration may be applied at a later stage (between \textit{DL0} and \textit{DL1a}) such that the results of the offline pipeline are of optimum quality. 
\item[DL0 \textit{(raw archived)}:]
Similar data to the \textit{R1} level, except serialised into files and stored for long-term archival. In order to achieve this with the excessively large data volume produced by \gls{cta}, \textit{Data Volume Reduction} must be performed to achieve two orders of magnitude reduction. The simplest form of reduction is known as zero-suppression, where only waveforms of pixels deemed to have signal are kept. This is one of the responsibilities of the \gls{oes}.
\item[DL1 \textit{(processed)}:]
The signal charge is extracted from the \textit{DL0} waveform data, and characterised in terms of its \textit{Hillas Parameters}. This process is handled by the \gls{dpps} offline data processing pipeline, of which \pkg{ctapipe} is a prototype. Further information about \pkg{ctapipe} can be found in Chapter~\ref{ch4-software}, and details about the processes involved in this stage are described in Chapter~\ref{ch6-reduction}.
\item[DL2 \textit{(reconstructed)}:]
The \textit{DL1} products (pixel charges and \textit{Hillas Parameters}) are used to reconstruct shower parameters including energy, direction, and source particle. At this point, the \textit{TEL multiplicity} is dropped, as the information from each telescope has been combined to perform the reconstruction, and the individual telescopes are no longer relevant. The operations involved in this stage are also performed by the DPPS offline pipeline, and are described in Chapter~\ref{ch6-reduction}.
\item[DL3 \textit{(reduced)}:]
Events are sorted into sets according to their type (e.g. gamma-ray candidates, electron candidates, selected hadron
candidates, etc.) alongside their reconstruction parameters. Associated instrumental response characterizations and any technical data needed for
science analysis are also included in this level.
\item[DL4 \textit{(science)}:]
The \textit{DL3} data are read into the one of the CTA tools within the \gls{suss} designed to support science data analysis. Two prototype tools developed for this purpose are \pkg{Gammapy} and \pkg{ctools} (Chapter~\ref{ch4-software}). These tools enable the construction of binned data products like spectra, sky maps, or light curves, enabling the analysis of astrophysical sources.
\item[DL5 \textit{(high-level)}:]
\textit{DL4} data is accumulated to generate \gls{cta} survey sky maps or the \gls{cta}
source catalogue.
\end{description}